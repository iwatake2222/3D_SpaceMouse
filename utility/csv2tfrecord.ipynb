{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csv2tfrecord.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iwatake2222/3D_SpaceMouse/blob/master/utility/csv2tfrecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu3053LCcZKq",
        "colab_type": "text"
      },
      "source": [
        "# Convert csv (Google cloud Auto ML Vision) format to TFRecord format\n",
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xwe_p0AR-ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G416TPrucgdE",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iTrIL9fSbdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from io import BytesIO\n",
        "import csv\n",
        "import argparse\n",
        "import pathlib\n",
        "\n",
        "def _bytes_feature(value):\n",
        "\t\"\"\"string / byte 型から byte_list を返す\"\"\"\n",
        "\tif isinstance(value, type(tf.constant(0))):\n",
        "\t\tvalue = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "\tif type(value) is list:\n",
        "\t\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\telse:\n",
        "\t\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "\t\"\"\"float / double 型から float_list を返す\"\"\"\n",
        "\tif type(value) is list:\n",
        "\t\treturn tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\telse:\n",
        "\t\treturn tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "\t\"\"\"bool / enum / int / uint 型から Int64_list を返す\"\"\"\n",
        "\tif type(value) is list:\n",
        "\t\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\telse:\n",
        "\t\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def conv_text2label(text):\n",
        "\tclass_text2label = {\n",
        "\t\t\t\"AsahiSuperDry\": 1,\n",
        "\t\t\t\"ClearAsahi\": 2,\n",
        "\t\t\t\"Hon_Kirin\": 3,\n",
        "\t\t\t\"Kinmugi\": 4,\n",
        "\t\t\t\"KIRIN_ICHI\": 5,\n",
        "\t\t\t\"Nodogoshi\": 6,\n",
        "\t\t\t\"PREMIUM_MALTS\": 7,\n",
        "\t\t\t\"SAPPORO\": 8,\n",
        "\t\t\t\"YEBISU\": 9,\n",
        "\t\t\t}\n",
        "\treturn class_text2label[text]\n",
        "\n",
        "def write_features_to_record(image_filename, features_for_one_image):\n",
        "\tfilename, ext = os.path.splitext(image_filename)\n",
        "\twith tf.io.TFRecordWriter(filename + \".tfrecord\") as writer:\n",
        "\t\timage = Image.open(image_filename)\n",
        "\t\timage_string = open(image_filename, \"rb\").read()\n",
        "\t\tfeature = {\n",
        "\t\t\t\t\"image/encoded\": _bytes_feature(image_string),\n",
        "\t\t\t\t\"image/filename\": _bytes_feature(image_filename.encode('utf-8')),\n",
        "\t\t\t\t\"image/source_id\": _bytes_feature(image_filename.encode('utf-8')),\n",
        "\t\t\t\t\"image/format\": _bytes_feature(ext[1:].encode('utf-8')),\n",
        "\t\t\t\t\"image/height\": _int64_feature(image.size[1]),\n",
        "\t\t\t\t\"image/width\": _int64_feature(image.size[0]),\n",
        "\t\t\t\t'image/depth': _int64_feature(len(image.split())),\n",
        "\t\t\t\t\"image/object/bbox/xmax\": _float_feature(list(map(float, [x[7] for x in features_for_one_image])) if len(features_for_one_image[0][3]) > 0 else []),\n",
        "\t\t\t\t\"image/object/bbox/xmin\": _float_feature(list(map(float, [x[3] for x in features_for_one_image])) if len(features_for_one_image[0][3]) > 0 else []),\n",
        "\t\t\t\t\"image/object/bbox/ymax\": _float_feature(list(map(float, [x[8] for x in features_for_one_image])) if len(features_for_one_image[0][3]) > 0 else []),\n",
        "\t\t\t\t\"image/object/bbox/ymin\": _float_feature(list(map(float, [x[4] for x in features_for_one_image])) if len(features_for_one_image[0][3]) > 0 else []),\n",
        "\t\t\t\t\"image/object/class/label\": _int64_feature(list(map(conv_text2label,[x[2] for x in features_for_one_image])) if len(features_for_one_image[0][3]) > 0 else []),\n",
        "\t\t\t\t\"image/object/class/text\": _bytes_feature([x[2].encode('utf-8') for x in features_for_one_image] if len(features_for_one_image[0][3]) > 0 else []),\n",
        "#\t\t\t\t\"image/object/difficult\": aaa,\n",
        "#\t\t\t\t\"image/object/truncated\": aaa,\n",
        "#\t\t\t\t\"image/object/view\": aaa,\n",
        "\t\t\t\t}\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\t\twriter.write(tf_example.SerializeToString())\n",
        "\n",
        "def convert_from_csv_to_frecord(path_to_csv):\n",
        "\twith open(path_to_csv) as f:\n",
        "\t\treader = csv.reader(f)\n",
        "\t\tdataset_for_one_image = []\n",
        "\t\tfor row in reader:\n",
        "\t\t\tif (len(dataset_for_one_image) > 0 and row[1] != dataset_for_one_image[-1][1]):\n",
        "\t\t\t\timage_filename = pathlib.Path(dataset_for_one_image[0][1]).name\n",
        "\t\t\t\twrite_features_to_record(image_filename, dataset_for_one_image)\n",
        "\t\t\t\tdataset_for_one_image = []    # clear\n",
        "\t\t\telse:\n",
        "\t\t\t\tpass\n",
        "\t\t\tdataset_for_one_image.append(row)\n",
        "\t\n",
        "\t\tif (len(dataset_for_one_image) > 0):\n",
        "\t\t\timage_filename = pathlib.Path(dataset_for_one_image[0][1]).name\n",
        "\t\t\twrite_features_to_record(image_filename, dataset_for_one_image)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFSQls8Uci8s",
        "colab_type": "text"
      },
      "source": [
        "## Execution\n",
        "*IMPORTANT*\n",
        "\n",
        "All image files must be placed in the same place as the current directory. (directory structure is ignored)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mIPWieTSrOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "72521590-dff7-4c68-8bf2-7a15bf25d9ef"
      },
      "source": [
        "%cd \"/content/drive/My Drive/temp/genarated_csv_dataset\"\n",
        "csv_filename = \"annotation.csv\"\n",
        "convert_from_csv_to_frecord(csv_filename)\n",
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/temp/genarated_csv_dataset\n",
            "20190922_201645.jpg  20190922_201645.tfrecord  annotation.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}